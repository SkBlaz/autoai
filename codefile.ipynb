{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d5e0d7a",
   "metadata": {},
   "source": [
    "# Classification Problem\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc551f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\r",
    "import numpy as np\r",
    "import pandas as pd\r",
    "import matplotlib.pyplot as plt\r",
    "import seaborn as se\r",
    "import warnings\r",
    "from sklearn.model_selection import train_test_split\r",
    "from sklearn.preprocessing import LabelEncoder\r",
    "from sklearn.metrics import classification_report,plot_confusion_matrix\r",
    "warnings.filterwarnings('ignore')\r\n",
    "import blobcity as bc\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51a9f2a",
   "metadata": {},
   "source": [
    "### Data Fetch\n",
    " Pandas is an open-source, BSD-licensed library providing high-performance,easy-to-use data manipulation and data analysis tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b280975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Fetch\r",
    "file='https://raw.githubusercontent.com/Thilakraj1998/Datasets_general/main/BreastCancer1.csv'\r",
    "df=pd.read_csv(file)\r",
    "df.head()\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc481158",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    " It is the process of reducing the number of input variables when developing a predictive model.Used to reduce the number of input variables to reduce the computational cost of modelling and,in some cases,to improve the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c7fb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected Columns\r",
    "features=['radius_mean', 'texture_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', 'radius_se', 'compactness_se', 'concavity_se', 'concave points_se', 'texture_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst', 'concave points_worst', 'symmetry_worst', 'fractal_dimension_worst']\r",
    "target='diagnosis'\r\n",
    "# X & Y\r",
    "X=df[features]\r",
    "Y=df[target]\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231453c7",
   "metadata": {},
   "source": [
    "### Data Encoding\n",
    " Converting the string classes data in the datasets by encoding them to integer either using OneHotEncoding or LabelEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5285b6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Target Encoding\r",
    "def EncodeY(Y):\r",
    "\tactual_target=np.sort(pd.unique(Y), axis=-1, kind='mergesort')\r",
    "\tY=LabelEncoder().fit_transform(Y)\r",
    "\tencoded_target=[xi for xi in range(len(actual_target))]\r",
    "\tprint('Encoded Target: {} to {}'.format(actual_target,encoded_target))\r",
    "\treturn Y\r",
    "Y=EncodeY(Y)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e28333",
   "metadata": {},
   "source": [
    "### Correlation Matrix\n",
    " In order to check the correlation between the features, we will plot a correlation matrix. It is effective in summarizing a large amount of data where the goal is to see patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0b1910",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=(18, 18))\r",
    "matrix = np.triu(X.corr())\r",
    "se.heatmap(X.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax, mask=matrix)\r",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25417605",
   "metadata": {},
   "source": [
    "### Train & Test\n",
    " The train-test split is a procedure for evaluating the performance of an algorithm.The procedure involves taking a dataset and dividing it into two subsets.The first subset is utilized to fit/train the model.The second subset is used for prediction.The main motive is to estimate the performance of the model on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0b97d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data split for training and testing\r",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=123)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede1fc19",
   "metadata": {},
   "source": [
    "### Neural Network/Deep Learning Model \n",
    "Deep learning is a subset of machine learning, which is essentially a neural network with three or more layers. These neural networks attempt to simulate the behavior of the human brain-albeit far from matching its ability-allowing it to 'learn' from large amounts of data. While a neural network with a single layer can still make approximate predictions, additional hidden layers can help to optimize and refine for accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9c8163",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = bc.load('PICKLE FILE PATH')\r",
    "#summary\r",
    "nn=model.model\r",
    "nn.summary()\n",
    "nn.fit(X_train,Y_train,epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f58d683",
   "metadata": {},
   "source": [
    "### Accuracy Metrics\n",
    " Performance metrics are a part of every machine learning pipeline. They tell you if you're making progress, and put a number on it. All machine learning models,whether it's linear regression, or a SOTA technique like BERT, need a metric to judge performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e0bdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\r",
    "y_pred=nn.predict(X_test)\r",
    "y_pred=np.round(y_pred)# Classification Report\r",
    "print(classification_report(Y_test,y_pred))\r\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
